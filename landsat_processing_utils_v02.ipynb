{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3910c57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import os\n",
    "import numpy as np\n",
    "import rioxarray as rxr\n",
    "import xarray as xr\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import box\n",
    "import earthpy.spatial as es\n",
    "from tqdm import tqdm\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d33a7b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Additional utils - may have to update to use rxr workflow\n",
    "# https://corteva.github.io/rioxarray/html/examples/resampling.html <- resampling with rxr\n",
    "\n",
    "def histogram_stretch(img, min_vals = None, max_vals = 99):\n",
    "    \"\"\"\n",
    "    Performs a histogram_stretch on an image. DO NOT use this for analytical workflows - \n",
    "    this should only be used to improve image visualization\n",
    "    \n",
    "    img: an unmasked 3D raster \n",
    "    \n",
    "    min_vals: percentile that you wish to crop to\n",
    "        will be np.zeros by default\n",
    "    max_vals: percentile that you wish to crop to\n",
    "        will be np.nanpercentile(img, 99) by default # crops to 99th percentile\n",
    "    \"\"\"\n",
    "    if img.ndim != 3:\n",
    "        print(\"ValueError: Your raster must have three dimensions.\")\n",
    "        return\n",
    "    \n",
    "    # This returns the max_valth percentile\n",
    "    max_vals = np.nanpercentile(img, max_vals, axis = (1,2)).reshape(img.shape[0],1,1) \n",
    "    # min_vals = np.nanmin(tcc_toa, axis = (1,2)).reshape(3,1,1) # Use this to stretch to minimum values\n",
    "    if min_vals is not None:\n",
    "        min_vals = np.nanpercentile(img, min_vals, axis = (1,2)).reshape(img.shape[0],1,1)\n",
    "    else:\n",
    "        min_vals = np.zeros(img.shape[0]).reshape(img.shape[0],1,1)\n",
    "    \n",
    "    # Perform normalization\n",
    "    img_stretched = (img - min_vals) / (max_vals - min_vals)\n",
    "    \n",
    "    # Clip values above 1\n",
    "    img_stretched[img_stretched > 1] = 1\n",
    "    \n",
    "    return img_stretched\n",
    "\n",
    "def landsat_l2_scaling(stacked_mb_raster):    \n",
    "    '''\n",
    "    stacked_mb_raster: filepath to stacked l2 raster to be scaled (must be ordered bands 1-X then 10)\n",
    "        OR 3D stacked numpy array (must be ordered bands 1-X then 10)\n",
    "    \n",
    "    returns 3D numpy array of the scaled, stacked bands as well as the profile information\n",
    "    '''\n",
    "    if isinstance(stacked_mb_raster, str):\n",
    "        with rio.open(stacked_mb_raster) as src:\n",
    "            profile = src.profile\n",
    "            stack = src.read()\n",
    "            src.close()\n",
    "    else:\n",
    "        stack = stacked_mb_raster\n",
    "\n",
    "    # change the stack from DNs to reflectances\n",
    "    # remember temperature uses a different scaling factor (temp is in Kelvin)\n",
    "    scaled_stack = stack[:-1,...] * 0.0000275 - 0.2\n",
    "    scaled_temp = stack[-1,...] * 0.00341802 + 149.0 \n",
    "\n",
    "    # need to change scaled_temp from 2D to 3D\n",
    "    scaled_stack = np.vstack((scaled_stack, np.expand_dims(scaled_temp, axis = 0))) \n",
    "    \n",
    "    return scaled_stack, profile\n",
    "\n",
    "def prep_training_data(raster, gdf, scale = False):\n",
    "    '''\n",
    "    Prepares X_train and y_train data from a raster image given a GeoDataFrame of classified polygons\n",
    "    \n",
    "    raster: Path to stacked 3D raster. If conducting scaling, 3D raster should be in the form (Bands 1-X, 10).\n",
    "    \n",
    "    gdf: GeoDataFrame containing labelled polygons. Must have \"geometry\" col and the labels col must be named \"labels\"\n",
    "        May want to adjust this in the future.\n",
    "        \n",
    "    scale: Flag to indicate if the raster should be scaled from DNs to reflectances. Current implementation only works\n",
    "        with Landsat Level 2 scaling. Please run process_folder() to do TOA scaling on Landsat level 1 products prior to using\n",
    "        this function.\n",
    "    '''\n",
    "\n",
    "    # note that although we have scaled_stack, rio.mask.mask requires a dataset in read mode\n",
    "    with rio.open(raster) as src:\n",
    "        profile = src.profile\n",
    "        \n",
    "        # To prep the data for ML analysis, we need two numpy arrays:\n",
    "        # X: a numpy array that contains all of the band data for the pixel\n",
    "        # y: the labels for training\n",
    "\n",
    "        # Creates an empty array with X columns, where X is the number of bands in the multiband raster\n",
    "        X_train = np.array([], dtype = np.float32).reshape(0, profile[\"count\"])\n",
    "        y_train = np.array([], dtype = np.string_) # labels for training\n",
    "        \n",
    "        # Iterate over each polygon in our landuse ground truth dataset\n",
    "        for index, row in gdf.iterrows():\n",
    "            feature = [row[\"geometry\"]]\n",
    "\n",
    "            # crop the image - mask function returns a tuple\n",
    "            out_image, out_transform = rio.mask.mask(src, feature, crop = True)\n",
    "\n",
    "            # out_image has a shape (8, height, width)\n",
    "            # Since this returns a rectangular array, and our shape is not rectangular, there will be\n",
    "            # a bunch of nodata - get rid of them.\n",
    "\n",
    "            # ~np.any(np.isnan(out_image), axis = 0) if any of the bands are np.nan\n",
    "\n",
    "            # note that this gets rid of any column that has ANY nans\n",
    "            # The following code returns a column for each band, with each row representing a pixel\n",
    "            out_image_trimmed = out_image[:, ~np.any(out_image == profile['nodata'], axis = 0)]\n",
    "\n",
    "            # We actually want this the other way around - we want a row for pixel, and a column for each\n",
    "            # band - so we transpose the image\n",
    "            out_image_trimmed = out_image_trimmed.T\n",
    "            \n",
    "            if scale:\n",
    "                out_bands = out_image_trimmed[:,:-1] * 0.0000275 - 0.2\n",
    "                out_temp = out_image_trimmed[:,-1] * 0.00341802 + 149.0 \n",
    "\n",
    "                out_raster = np.hstack((out_bands, np.expand_dims(out_temp, axis = 1)))\n",
    "            else:\n",
    "                out_raster = out_image_trimmed\n",
    "            \n",
    "            # We append the labels to the answer array equal to the number of pixels:\n",
    "            # Remember to put brackets around the row[\"LULC\"], or else you'll get \"forestforestforest\"\n",
    "            # out_image_trimmed.shape[0] is the number of pixels in the training data\n",
    "            y_train = np.append(y_train, [row[\"labels\"]] * out_raster.shape[0])\n",
    "\n",
    "            # vstack is like concat for rows. Note that to vstack correctly, the array tuple that you feed\n",
    "            # to vstack must have the same column dimension\n",
    "            X_train = np.vstack((X_train, out_raster))\n",
    "\n",
    "    src.close()\n",
    "    \n",
    "    return X_train, y_train\n",
    "\n",
    "# Run a conservative cloud detection\n",
    "def qa_pixel_interp_aggressive(number):\n",
    "    '''\n",
    "    Helps interpret the 16bit data in the landsat qa pixels\n",
    "    \n",
    "    returns True if there is mid confidence cirrus, snow/ice, cloud shadow, OR clouds\n",
    "    '''\n",
    "    binary = bin(number)[2:].zfill(16)\n",
    "    \n",
    "    # if medium to high confidence cirrus, snow/ice, cloud shadow, and clouds\n",
    "    if int(binary[:2]) > 1:\n",
    "        return True\n",
    "    elif int(binary[2:4]) > 1:\n",
    "        return True\n",
    "    elif int(binary[4:6]) > 1:\n",
    "        return True\n",
    "    elif int(binary[6:8]) > 1:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "def qa_pixel_interp_conservative(number):\n",
    "    '''\n",
    "    Helps interpret the 16bit data in the landsat qa pixels\n",
    "    \n",
    "    returns True if there is mid confidence cirrus, snow/ice, cloud shadow, OR clouds\n",
    "    '''\n",
    "    binary = bin(number)[2:].zfill(16)\n",
    "    \n",
    "    # if high confidence cirrus, snow/ice, cloud shadow, and clouds\n",
    "    # 01 - low, 10 - medium, 11 - high\n",
    "    if int(binary[:2]) > 10:\n",
    "        return True\n",
    "    elif int(binary[2:4]) > 10:\n",
    "        return True\n",
    "    elif int(binary[4:6]) > 10:\n",
    "        return True\n",
    "    elif int(binary[6:8]) > 10:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "def qa_pixel_interp_conserv_water(number):\n",
    "    '''\n",
    "    Helps interpret the 16bit data in the landsat qa pixels\n",
    "    \n",
    "    returns True if there is mid confidence cirrus, snow/ice, cloud shadow, clouds OR WATER\n",
    "    '''\n",
    "    binary = bin(number)[2:].zfill(16)\n",
    "    \n",
    "    # if high confidence cirrus, snow/ice, cloud shadow, and clouds\n",
    "    # 01 - low, 10 - medium, 11 - high\n",
    "    if int(binary[:2]) > 10:\n",
    "        return True\n",
    "    elif int(binary[2:4]) > 10:\n",
    "        return True\n",
    "    elif int(binary[4:6]) > 10:\n",
    "        return True\n",
    "    elif int(binary[6:8]) > 10:\n",
    "        return True\n",
    "    # if water return true\n",
    "    elif int(binary[8]) == 1:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "def apply_array_func(func, x):\n",
    "    '''\n",
    "    Applies a function element-wise across a 1D array\n",
    "    '''\n",
    "    return np.array([func(xi) for xi in x])\n",
    "\n",
    "def run_qa_parser(qa_raster, func):\n",
    "    '''\n",
    "    Accepts a QA_PIXEL array bundled with Landsat l2 product consisting of 16 bit unsigned integers.\n",
    "    Generates a binary cloud mask using the function provided.\n",
    "    \n",
    "    qa_raster: numpy array of qa_raster. Works both stacked and unstacked.\n",
    "    func: interpretation scheme to be used to generate the cloud mask. Current schemes include:\n",
    "        qa_pixel_interp_conserv_water: conservative cloud detection, also masks water bodies\n",
    "        qa_pixel_interp_conservative: conservative cloud detection\n",
    "        qa_pixel_interp_aggressive: aggressive cloud detection\n",
    "    \n",
    "    Returns a squeezed binary cloud mask\n",
    "    '''\n",
    "    unique_vals = np.unique(qa_raster)\n",
    "    masked_vals = apply_array_func(func, unique_vals)\n",
    "    masked_vals = unique_vals[masked_vals]\n",
    "    cl_mask = np.isin(qa_raster, masked_vals)\n",
    "    \n",
    "    return cl_mask.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "227efbe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_mtl(mtl_file):\n",
    "    \"\"\"\n",
    "    Parses the landsat metadata file into a dictionary of dictionaries.\n",
    "    \n",
    "    Dictionary is split into several sub-dicts including PRODUCT_CONTENTS and IMAGE_ATTRIBUTES\n",
    "    \"\"\"\n",
    "    \n",
    "    with open(mtl_file) as f:\n",
    "        lines = f.readlines()\n",
    "        f.close()\n",
    "\n",
    "    clean_lines = [element.strip(\"\\n\").strip() for element in lines]\n",
    "\n",
    "    ### PARSE THE MTL FILE INTO A DICTIONARY ###\n",
    "    # Find all major groups in the metadata\n",
    "    groups = [element for element in clean_lines if element.startswith(\"GROUP\")]\n",
    "\n",
    "    group_dict = dict()\n",
    "\n",
    "    # We don't need the overarching metadata group\n",
    "    for group in groups[1:]:\n",
    "        # Return the part of list that the group contains\n",
    "        contents = clean_lines[clean_lines.index(group)+1:clean_lines.index(f\"END_{group}\")]\n",
    "\n",
    "        data_dict = {}\n",
    "        # Iterate through the elements in the list\n",
    "        for element in contents:\n",
    "            # Split the element by \"=\"\n",
    "            parts = element.split(\"=\")\n",
    "            if len(parts) == 2:\n",
    "                # Assign A as key and B as value to the dictionary\n",
    "                key = parts[0].strip()  # Remove leading/trailing whitespace\n",
    "                value = parts[1].strip()  # Remove leading/trailing whitespace\n",
    "                data_dict[key] = value.strip(\"\\\"\") # Remove quotation marks\n",
    "\n",
    "        group_dict[group.replace(\"GROUP = \", \"\", 1)] = data_dict\n",
    "    \n",
    "    return group_dict\n",
    "\n",
    "def toa_reflectance(raster, band_num, metadata, sun_corr = True):\n",
    "    \"\"\"\n",
    "    raster: requires a 2D xarray as read by rxr.open_rasterio\n",
    "    NB - array should be masked since landsat uses 0 for np.nan\n",
    "    \n",
    "    band_num: the landsat band number associated with that raster\n",
    "    sun_corr: indicate if you want sun elevation correction (default true)\n",
    "    \n",
    "    returns the landsat level 1 product raster corrected for TOA\n",
    "    Note that these are center image sun corrected - you can do pixel level sun correction but it\n",
    "    takes a lot more work\n",
    "    \"\"\"\n",
    "    # Get TOA reflectance\n",
    "    toa_ref = raster * float(metadata[\"LEVEL1_RADIOMETRIC_RESCALING\"][f\"REFLECTANCE_MULT_BAND_{band_num}\"]) + float(metadata[\"LEVEL1_RADIOMETRIC_RESCALING\"][f\"REFLECTANCE_ADD_BAND_{band_num}\"])\n",
    "    \n",
    "    # Correct for sun elevation\n",
    "    if sun_corr:\n",
    "        toa_ref = toa_ref / np.sin(np.deg2rad(float(metadata[\"IMAGE_ATTRIBUTES\"][\"SUN_ELEVATION\"])))\n",
    "    \n",
    "    # Clip any values that are larger than 1 to 1\n",
    "    # must use .where() method\n",
    "    toa_ref.where(toa_ref <= 1, 1)\n",
    "    \n",
    "    # toa_ref[toa_ref > 1] = 1 \n",
    "    \n",
    "    return toa_ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2246b8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### variables required: \n",
    "## filepath - folder containing the MTL as well as the landsat images\n",
    "## mask = None - shapefile containing the masking polygons. \n",
    "## bounds = True - Bool, whether the data should be masked by the polygon exactly or if the raster should be masked by the total \n",
    "##          bounds of the polygon. Default uses total_bounds of polygon (results in rectangular image)\n",
    "## sun_corr = True - Bool, whether TOA should take into account sun correctoin\n",
    "## stack = True - Bool, whether a stacked raster containing the cropped, TOA corrected rasters should be created\n",
    "## outdir = None - output directory where the output files should be saved. If not specified, save in the folder where this program\n",
    "##          is located\n",
    "\n",
    "def process_folder(filepath, mask = None, bounds = True, sun_corr = True, stack = True, outdir = None):\n",
    "    \"\"\"\n",
    "    Processes folder containing Landsat Level 1 Products. Includes TOA, cropping and stacking\n",
    "    \n",
    "    \n",
    "    filepath - folder containing the MTL as well as the landsat images\n",
    "    mask = None - shapefile containing the masking polygons. CRS will automatically be converted to\n",
    "            landsat CRS\n",
    "    bounds = True - Bool, whether the data should be masked by the polygon exactly or if the raster \n",
    "            should be masked by the total bounds of the polygon. Default uses total_bounds of \n",
    "            polygon (results in rectangular image)\n",
    "    sun_corr = True - Bool, whether TOA should take into account sun correctoin\n",
    "    stack = True - Bool, whether a stacked raster containing the cropped, TOA corrected rasters should \n",
    "            be created\n",
    "    outdir = None - output directory where the output files should be saved. If not specified,\n",
    "            save in the folder where this program is located\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    # identify the mtl_file\n",
    "    mtl_file = glob(os.path.join(filepath, '*MTL.txt'))\n",
    "\n",
    "    # If no mtl_file found or more than one mtl_file found\n",
    "    if len(mtl_file) != 1:\n",
    "        print('No MTL file found or more than one MTL file found. Please check the folder.')\n",
    "        return\n",
    "\n",
    "    # Error handling if the metadata file can't be read\n",
    "    try:\n",
    "        metadata = parse_mtl(mtl_file[0])\n",
    "    except:\n",
    "        print(\"Metadata could not be read.\")\n",
    "        return\n",
    "\n",
    "    # Find all bands from the MTL file\n",
    "    filenames = [value for key, value in metadata[\"PRODUCT_CONTENTS\"].items() if key.startswith(\"FILE_NAME_BAND\")]\n",
    "\n",
    "    # convert to the correct filenames\n",
    "    filenames = [os.path.join(filepath, filename) for filename in filenames]\n",
    "\n",
    "    band_list = []\n",
    "    target_crs = es.crs_check(filenames[0])\n",
    "\n",
    "    for file in tqdm(filenames):\n",
    "        band_num = int(file.split(\"B\")[1].split(\".\")[0])\n",
    "\n",
    "        # print(f'Processing band {band_num}...')\n",
    "\n",
    "        # Skip band 8 completely (panchromatic band)\n",
    "        if band_num == 8:\n",
    "            continue\n",
    "\n",
    "        with rxr.open_rasterio(file, masked = True) as ds:\n",
    "\n",
    "            # If mask has been specified, crop before loading\n",
    "            if mask is not None:\n",
    "                # reproject the polygon to the same CRS as the landsat image\n",
    "                polygon = gpd.read_file(mask)\n",
    "                polygon = polygon.to_crs(target_crs)\n",
    "\n",
    "                # if \n",
    "                if bounds:\n",
    "                    xmin, ymin, xmax, ymax = polygon.total_bounds\n",
    "                    target_shapefile = box(np.floor(xmin), np.floor(ymin), np.ceil(xmax), np.ceil(ymax))\n",
    "                    ds = ds.rio.clip([target_shapefile], from_disk = True).squeeze()\n",
    "                else:\n",
    "                    ds = ds.rio.clip(polygon.geometry, from_disk = True).squeeze()\n",
    "\n",
    "            if mask:\n",
    "                savename = f'{os.path.basename(file).split(\".\")[0]}_TOA_crop.tif'\n",
    "            else:\n",
    "                savename = f'{os.path.basename(file).split(\".\")[0]}_TOA.tif'\n",
    "\n",
    "            if outdir is not None:\n",
    "                out_path = os.path.join(outdir, savename)\n",
    "            else:\n",
    "                out_path = savename\n",
    "\n",
    "            # catch temperature bands and save raster\n",
    "            if band_num > 9:\n",
    "                band_list.append(ds)\n",
    "                ds.rio.to_raster(out_path)\n",
    "                continue\n",
    "\n",
    "            # Do TOA reflectance correction\n",
    "            ds = toa_reflectance(ds, band_num, metadata, sun_corr = sun_corr)\n",
    "\n",
    "            # adjust nodata value to np.nan (since 0 is used for DNs)\n",
    "            # NB: This is extremely important - if you do not explicitly state a nodata value, you won't be able to \n",
    "            # save xr.Dataset() - raises ufunc isnan error\n",
    "            ds = ds.rio.write_nodata(np.nan, inplace = True)\n",
    "            band_list.append(ds)\n",
    "            \n",
    "            # Save raster\n",
    "            ds.rio.to_raster(out_path)\n",
    "            \n",
    "            ds.close()\n",
    "\n",
    "    if stack:\n",
    "        print('Stacking...')\n",
    "        \n",
    "        # Use xarray dataset to insert band names\n",
    "        \n",
    "        bands=['Coastal','Blue','Green','Red','NIR','SWIR-1','SWIR-2','Cirrus', 'TIRS-1', 'TIRS-2']\n",
    "        \n",
    "        stacked_array = xr.Dataset()\n",
    "        \n",
    "        for idx, band in enumerate(bands):\n",
    "            stacked_array[band] = band_list[idx]\n",
    "            \n",
    "        # get landsat code\n",
    "        stack_name = metadata[\"PRODUCT_CONTENTS\"][\"LANDSAT_PRODUCT_ID\"]\n",
    "\n",
    "        if mask:\n",
    "            stack_name = f'{stack_name}_TOA_crop_stacked.tif'\n",
    "        else:\n",
    "            stack_name = f'{stack_name}_TOA_stacked.tif'\n",
    "\n",
    "        if outdir is not None: \n",
    "            stacked_array.rio.to_raster(os.path.join(outdir, stack_name))\n",
    "        else:\n",
    "            stacked_array.rio.to_raster(stack_name)\n",
    "            \n",
    "    print('TOA processing complete.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d116cea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    ### useful tutorial https://docs.python.org/3/howto/argparse.html#argparse-tutorial\n",
    "    parser = argparse.ArgumentParser(\n",
    "        description='Calculates TOA reflectance for Level 1 Landsat products. Additional flags can be set to crop, \\\n",
    "        stack, and ignore sun elevation correction.')\n",
    "\n",
    "    # add positional argument (i.e., required argument)\n",
    "    parser.add_argument('filepath',\n",
    "                       help = 'Path to folder containing all Landsat bands and MTL file.')\n",
    "\n",
    "    # optional flags - the name of the variable is the -- option\n",
    "    parser.add_argument('-m', '--mask', help = 'Provide a shapefile that the images will be cropped to') \n",
    "\n",
    "    # on/off flags - action indicates what the program should do\n",
    "    # if flag is called (default will be the opposite for on/off)\n",
    "    parser.add_argument('-b', '--bounds', action='store_false', help = \"Add this flag if you want to crop the raster to exact polygon geometries. Otherwise, the rasters will be cropped to the total bounds of the shapefile (default; results in rectangular raster)\")\n",
    "    parser.add_argument('-s', '--stack', action='store_false', help = 'Add this flag if you DONT want to create a stacked raster of the images') \n",
    "    parser.add_argument('-c', '--sun_corr', action='store_false', help = \"Add this flag if you DON'T want to do a sun elevation correction\")\n",
    "    parser.add_argument('-o', '--outdir', help = \"Specify an output folder to save TOA corrected images\")\n",
    "\n",
    "\n",
    "    ### Preview arguments\n",
    "    # parser.parse_args('LC08 -c -m test.geojson'.split(' '))\n",
    "    \n",
    "    # grab arguments from command line\n",
    "    args = parser.parse_args()\n",
    "    \n",
    "    # calculate TOA\n",
    "    process_folder(args.filepath, \n",
    "                   mask = args.mask, \n",
    "                   stack = args.stack, \n",
    "                   sun_corr = args.sun_corr, \n",
    "                   outdir = args.outdir,\n",
    "                   bounds = args.bounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "148fadc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 11/11 [00:02<00:00,  5.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacking...\n",
      "TOA processing complete.\n",
      "CPU times: total: 2.78 s\n",
      "Wall time: 3.41 s\n"
     ]
    }
   ],
   "source": [
    "# Speed of raster\n",
    "# %%time\n",
    "# process_folder('LC08_L1TP_180035_20230710_20230718_02_T1', outdir = 'Test Outputs', mask = 'rhodes.geojson')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:gdal]",
   "language": "python",
   "name": "conda-env-gdal-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
